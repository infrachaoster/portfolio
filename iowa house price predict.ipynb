{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7c298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from category_encoders import MEstimateEncoder\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497758ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv("portfolio/train.csv", index_col='Id')\n", 
    "df_test = pd.read_csv("portfolio/test.csv", index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b16463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numtrans = SimpleImputer(strategy='mean')\n",
    "cattrans = make_pipeline(SimpleImputer(strategy='most_frequent'), OrdinalEncoder())\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83f16634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    return ColumnTransformer(transformers=[\n",
    "        ('num', numtrans, data.select_dtypes('number').columns), \n",
    "        ('cat', cattrans, data.select_dtypes(exclude='number').columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a9cd5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossFoldEncoder:\n",
    "    def __init__(self, encoder, **kwargs):\n",
    "        self.encoder_ = encoder\n",
    "        self.kwargs_ = kwargs  \n",
    "        self.cv_ = KFold(n_splits=5)\n",
    "\n",
    "    def fit_transform(self, X, y, cols):\n",
    "        self.fitted_encoders_ = []\n",
    "        self.cols_ = cols\n",
    "        X_encoded = []\n",
    "        for idx_encode, idx_train in self.cv_.split(X):\n",
    "            fitted_encoder = self.encoder_(cols=cols, **self.kwargs_)\n",
    "            fitted_encoder.fit(\n",
    "                X.iloc[idx_encode, :], y.iloc[idx_encode],\n",
    "            )\n",
    "            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[cols])\n",
    "            self.fitted_encoders_.append(fitted_encoder)\n",
    "        X_encoded = pd.concat(X_encoded)\n",
    "        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n",
    "        return X_encoded\n",
    "\n",
    "    def transform(self, X):\n",
    "        from functools import reduce\n",
    "\n",
    "        X_encoded_list = []\n",
    "        for fitted_encoder in self.fitted_encoders_:\n",
    "            X_encoded = fitted_encoder.transform(X)\n",
    "            X_encoded_list.append(X_encoded[self.cols_])\n",
    "        X_encoded = reduce(\n",
    "            lambda x, y: x.add(y, fill_value=0), X_encoded_list\n",
    "        ) / len(X_encoded_list)\n",
    "        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n",
    "        return X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "922dd087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(X, y, model=XGBRegressor()):\n",
    "    preproc = preprocess(X)\n",
    "    presc = make_pipeline(preproc, ss)\n",
    "    X = pd.DataFrame(presc.fit_transform(X), columns=X.columns)\n",
    "    log_y = np.log(y)\n",
    "    score = cross_val_score(model, X, log_y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    score = -1 * score.mean()\n",
    "    score = np.sqrt(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0348d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y):\n",
    "    preproc = preprocess(X)\n",
    "    X = pd.DataFrame(preproc.fit_transform(X), columns=X.columns)\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5051ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.SalePrice\n",
    "X = df.drop('SalePrice', axis=1)\n",
    "X_test = df_test.copy()\n",
    "encoder = CrossFoldEncoder(MEstimateEncoder, m=1)\n",
    "df = df.join(encoder.fit_transform(X, y, cols=['Neighborhood']))\n",
    "df_test = df_test.join(encoder.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5956af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('SalePrice', axis=1)\n",
    "feat = make_mi_scores(X, y)\n",
    "bestfeat = [col for col in feat.index if feat[col] != 0]\n",
    "X_train = df[bestfeat].copy()\n",
    "X_test = df_test[bestfeat].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1896afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def objective(trial):\n",
    "    #xgb_params = dict(\n",
    "        #max_depth=trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        #learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n",
    "        #n_estimators=trial.suggest_int(\"n_estimators\", 1000, 8000),\n",
    "        #min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        #colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        #subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        #reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n",
    "        #reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n",
    "    #)\n",
    "    #xgb = XGBRegressor(**xgb_params)\n",
    "    #return score_dataset(X_train, y, xgb)\n",
    "\n",
    "#study = optuna.create_study(direction=\"minimize\")\n",
    "#study.optimize(objective, n_trials=10)\n",
    "#xgb_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0982c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'max_depth': 7, \n",
    "    'learning_rate': 0.015269070049790742, \n",
    "    'n_estimators': 2264, \n",
    "    'min_child_weight': 1, \n",
    "    'colsample_bytree': 0.28087976809624743, \n",
    "    'subsample': 0.511459954866386, \n",
    "    'reg_alpha': 0.03308814376776799, \n",
    "    'reg_lambda': 0.00031171990336833566\n",
    "}\n",
    "xgb = XGBRegressor(**xgb_params)\n",
    "preproc = preprocess(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2209d9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11850391307586257"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(preproc, ss, xgb)\n",
    "pipe.fit(X_train, np.log(y))\n",
    "preds = np.exp(pipe.predict(X_test))\n",
    "score_dataset(X_train, y, xgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
